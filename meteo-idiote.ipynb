{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meteo idiote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyser les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp [278.55 277.35 276.85 ... 281.05 282.35 282.55]\n",
      "hour [     0      0      0 ... 210000 210000 210000]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from numpy import hsplit\n",
    "my_data = genfromtxt('iadata.csv', delimiter=';', dtype=\"f4,u4,S8\", names=True)\n",
    "(temp,hour,label)=my_data['t'],my_data['h'],my_data['season']\n",
    "print (\"temp\",temp)\n",
    "print (\"hour\",hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "my_rec = my_data.view(np.recarray)\n",
    "plt.plot(my_rec.h,my_rec.t,'b.')\n",
    "#plt.ylim (0.,210000)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(my_rec.season,my_rec.t,'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données montrent que le modèle ne sera pas pertinent entre 275°K (2°c) et 295°C (22°C).\n",
    "On s'en doutait..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données d'entrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature en K :  [278.55 277.35 276.85 ... 281.05 282.35 282.55]\n",
      "Temperature normalisee :  [0.79585713 0.7924286  0.791      ... 0.803      0.8067143  0.80728567]\n",
      "Heure en String :  [     0      0      0 ... 210000 210000 210000]\n",
      "Heure normalisee :  [0.    0.    0.    ... 0.875 0.875 0.875]\n"
     ]
    }
   ],
   "source": [
    "from keras import utils\n",
    "print('Temperature en K : ',temp)\n",
    "#temp_normalized = utils.normalize(temp)\n",
    "temp_normalized = temp/350\n",
    "print('Temperature normalisee : ', temp_normalized)\n",
    "print('Heure en String : ',hour)\n",
    "hour_normalized = hour/240000\n",
    "print('Heure normalisee : ', hour_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79585713 0.        ]\n",
      " [0.79242861 0.        ]\n",
      " [0.79100001 0.        ]\n",
      " ...\n",
      " [0.80299997 0.875     ]\n",
      " [0.8067143  0.875     ]\n",
      " [0.80728567 0.875     ]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "from numpy import stack\n",
    "feature=stack((temp_normalized,hour_normalized),axis=1)\n",
    "print(feature)\n",
    "\n",
    "feature = feature.reshape((161449,2))\n",
    "feature = feature.astype('float32')\n",
    "\n",
    "print(feature.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.819, 0.   ], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature[6819]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8126421"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import average\n",
    "average(feature.T[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer les variables de sortie (les saisons) en vecteur de probabilité de saison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'winter', b'winter', b'winter', ..., b'winter', b'winter',\n",
       "       b'winter'], dtype='|S8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " ...\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "len(label)\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "transformed_label = encoder.fit_transform(label)\n",
    "print(transformed_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from keras.preprocessing.text import Tokenizer\n",
    "#tokenizer = Tokenizer(char_level=True)\n",
    "#tokenizer.fit_on_texts(label)\n",
    "#sequence_of_int = tokenizer.texts_to_sequences(label)\n",
    "#print (sequence_of_int)\n",
    "#from keras.utils import to_categorical\n",
    "#new_label= to_categorical(label, num_classes=4, dtype='int32')\n",
    "#new_label= to_categorical(label, num_classes=4)\n",
    "#print (new_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "transformed_label[6819]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du réseau de neurone et compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu',input_dim = 2))\n",
    "network.add(layers.Dense(4, activation='softmax'))\n",
    "#definition de la fonction de perte et de l'algo d'optim\n",
    "network.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement et évaluation de l'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : séparer les variables d'entrainbement et de contrôle du modèle (il doit y avoir une fonction pour ça)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "161449/161449 [==============================] - 1s 9us/step - loss: 1.3707 - acc: 0.3121\n",
      "Epoch 2/5\n",
      "161449/161449 [==============================] - 1s 7us/step - loss: 1.2684 - acc: 0.4474\n",
      "Epoch 3/5\n",
      "161449/161449 [==============================] - 1s 8us/step - loss: 1.1642 - acc: 0.4791\n",
      "Epoch 4/5\n",
      "161449/161449 [==============================] - 1s 7us/step - loss: 1.1128 - acc: 0.4869\n",
      "Epoch 5/5\n",
      "161449/161449 [==============================] - 1s 8us/step - loss: 1.0875 - acc: 0.4905\n",
      "161449/161449 [==============================] - 1s 9us/step\n",
      "test_acc: 0.48962830367484467\n"
     ]
    }
   ],
   "source": [
    "network.fit(feature, transformed_label,epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_acc = network.evaluate(feature, transformed_label)\n",
    "print ('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction d'été à midi 32°C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.5496850e-03 5.0528873e-02 9.4169956e-01 2.2178818e-04]]\n",
      "[b'summer']\n"
     ]
    }
   ],
   "source": [
    "prediction = network.predict(np.array([[(32.+273.15)/350., 120000./240000.]]))\n",
    "print(prediction)\n",
    "predicted_label = encoder.inverse_transform(prediction)\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction d'hiver à minuit -5°C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2237666  0.0657198  0.00622501 0.7042886 ]]\n",
      "[b'winter']\n"
     ]
    }
   ],
   "source": [
    "prediction = network.predict(np.array([[(273.15-5)/350., (0./240000.)]]))\n",
    "print(prediction)\n",
    "predicted_label = encoder.inverse_transform(prediction)\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = network.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "#network.save_weights(\"model.h5\")\n",
    "network.save(\"model.h5\")\n",
    "# save to tensorflowjs\n",
    "#import tensorflowjs as tfjs\n",
    "#tfjs.converters.save_keras_model(network)\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Temperature=10.\n",
    "Heure=30000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les probas sont [[0.2842217  0.31012064 0.27595216 0.12970549]]\n",
      "La prédiction est  [b'spring']\n"
     ]
    }
   ],
   "source": [
    "prediction = loaded_model.predict(np.array([[(273.15+Temperature)/350, Heure/240000.]]))\n",
    "print(\"Les probas sont\" ,prediction)\n",
    "predicted_label = encoder.inverse_transform(prediction)\n",
    "print(\"La prédiction est \" ,predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
